{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing analogical explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from math import *\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# FOR CSV\n",
    "from pandas import read_csv\n",
    "\n",
    "# FOR utilities\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAIN PROCESS\n",
    "Create a sample S, pick a random d in S, then compute c as the nearest neighbor of d in a different class. Compute the profile of (c,d) then look for the number of pairs (a,b) with same profile and compute confidence. Consider c and confidence as an explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************************************************************\n",
      "Dataset: realDatasets/12-vote/data.csv -dimension: 16 -number of rows: 435 -initial size: 435\n",
      "Dataset: realDatasets/12-vote/data.csv -dimension: 16 -number of rows: 435 -initial size: 435\n",
      "Total pairs (a,b): 94395  -matching pairs i.e. such that a:b::c:d 1877  -matching pairs with different classes: 1549\n",
      "1) We have found 3 relevant attributes among 16 which are: [3, 4, 12] .\n",
      "Our explanations why vector D: [\"'n'\" '?' \"'y'\" \"'n'\" \"'n'\" \"'n'\" \"'y'\" \"'y'\" \"'y'\" \"'y'\" \"'y'\" \"'n'\"\n",
      " \"'n'\" \"'y'\" \"'y'\" \"'y'\"] is in class 'democrat' :\n",
      "2) C [\"'y'\" \"'y'\" \"'y'\" \"'y'\" \"'n'\" \"'n'\" \"'y'\" \"'y'\" \"'y'\" \"'y'\" \"'y'\" \"'n'\"\n",
      " \"'n'\" \"'y'\" \"'n'\" \"'y'\"] is one of the nearest neighbours of D and C is in class 'republican'\n",
      "3) We have 82 % of confidence that attribute(s) [4] cause(s) the change of class.\n",
      "[1]\n",
      "***************************************************************\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nx_labels = [\\n    \"Adul.\",\\n    \"Bach\",\\n    \"Car\",\\n    \"Ches.\",\\n    \"Cont.\",\\n    \"Dmft\",\\n    \"Dres.\",\\n    \"Mush.\",\\n    \"Phis.\",\\n    \"Port.\",\\n    \"Scho.\",\\n    \"Vote\",\\n]\\nbar1 = dimension_list\\ncolor1 = \"blue\"\\nlabel1 = \"dataset dimension\"\\nbar2 = average_num_of_features_list\\ncolor2 = \"red\"\\nlabel2 = \"average used features\"\\ny_label = \"Num of features\"\\nshow_bar(bar1, color1, label1, bar2, color2, label2, x_labels, y_label, legend=True)\\n\\nbar1 = average_confidence_list\\nlabel1 = \"Confidence between 0 and 1\"\\nbar2 = average_confidence_list\\ny_label = \"Confidence between 0 and 1\"\\nshow_bar(bar1, color1, label1, bar2, color1, label1, x_labels, y_label, legend=False)\\n\\n# EXPERIMENT SAMPLE SIZE IMPACT ON HIGH DIMENSIONAL DATASET ADULT - PHISHING - PORTUGAL BANK\\n#dataset=filename1\\ndataset=filename9\\n#dataset=filename10\\nnumber_of_test=10\\ndata_init, _, _, _, _ = load_dataset(dataset)\\naverage_confidence_for_size_list=[]\\nsize_list=[500,1000,1500,2000]\\nfor size in size_list: #           #,1500,2000,3000,5000]:\\n    print(\"SIZE:\",size)\\n    total_confidence_for_size=0\\n    for i in range(number_of_test):\\n        #print(\"TEST:\",i)\\n        data = generate_sample_set(data_init, size)\\n        row_number = data.shape[0]\\n        (\\n            len_set_of_pairs,\\n            global_list_of_relevant_attributes,\\n            d,\\n            c,\\n            alpha,\\n            beta,\\n            actual_relevant_attributes,\\n        ) = explanation_loop(data,max_distance)\\n        try:\\n            confidence = alpha / beta\\n        except:\\n            confidence = 0\\n        total_confidence_for_size += confidence\\n        print(total_confidence_for_size)\\n    average_confidence_for_size= total_confidence_for_size / number_of_test\\n    average_confidence_for_size_list.append(average_confidence_for_size)\\n    \\nprint(dataset,average_confidence_for_size_list)\\n\\nt = [500,1000,1500,2000]:\\na = [0.7085887796414112, 0.5210526315789473, 0.7606590452661688, 0.9487870619946092]\\nb = [0.6545698924731183, 0.8443478260869565, 0.5950847293887664, 0.308874439211239 ]\\nc = [0.6675924096854329, 0.5203873482467506, 0.3847218357931196, 0.49149181819953736 ]\\n\\nplt.plot(t, list(zip(a, b, c)),label=[\\'Adul.\\', \\'Phis.\\', \\'Port.\\']);\\n#plt.plot(t, a, t, b, t, c, label=[\\'Adul\\', \\'Phis\\', \\'Port\\'])\\nplt.legend()\\nplt.show()\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# HYPER PARAMETERS\n",
    "max_distance = 5\n",
    "\n",
    "# CREATE AND LOAD SYNTHETIC DATASET ACCORDING TO 4 PARAMETERS\n",
    "f = g_example\n",
    "built_in_dimension = 5\n",
    "sample_size = 2 ** (built_in_dimension - 1)  # half size\n",
    "sample_size = min(1000, sample_size)\n",
    "categorical_range = 1\n",
    "# dataset0 = create_categorical_dataset(f, built_in_dimension, sample_size, categorical_range)\n",
    "dataset_example = \"example/sampleSize10-dim5WithNoise.csv\"\n",
    "\n",
    "# LOADING REAL DATASETS\n",
    "folder_real_data = \"realDatasets/\"\n",
    "data_filename = \"data.csv\"\n",
    "filename1 = folder_real_data + \"1-adult/\" + data_filename\n",
    "filename2 = folder_real_data + \"2-bach/\" + data_filename\n",
    "filename3 = folder_real_data + \"3-cars/\" + data_filename\n",
    "filename4 = folder_real_data + \"4-chess/\" + data_filename\n",
    "filename5 = folder_real_data + \"5-contraception/\" + data_filename\n",
    "filename6 = folder_real_data + \"6-dmft/\" + data_filename\n",
    "filename7 = folder_real_data + \"7-dress/\" + data_filename\n",
    "filename8 = folder_real_data + \"8-mushrooms/\" + data_filename\n",
    "filename9 = folder_real_data + \"9-phishing/\" + data_filename\n",
    "filename10 = folder_real_data + \"10-portugalBank/\" + data_filename\n",
    "filename11 = folder_real_data + \"11-school_grade/\" + data_filename\n",
    "filename12 = folder_real_data + \"12-vote/\" + data_filename\n",
    "\n",
    "# MAIN PROGRAM\n",
    "filename_list = [\n",
    "    filename1,\n",
    "    filename2,\n",
    "    filename3,\n",
    "    filename4,\n",
    "    filename5,\n",
    "    filename6,\n",
    "    filename7,\n",
    "    filename8,\n",
    "    filename9,\n",
    "    filename10,\n",
    "    filename11,\n",
    "    filename12,\n",
    "]\n",
    "filename_list = [filename12]\n",
    "number_of_test = 1\n",
    "dimension_list = []\n",
    "average_num_of_features_list = []\n",
    "average_confidence_list = []\n",
    "for dataset in filename_list:\n",
    "    print(\"***************************************************************\")\n",
    "    number_of_explanatory_features_list = []\n",
    "    total_confidence = 0\n",
    "    for i in range(number_of_test):\n",
    "        data, X, y, dimension, initial_size = load_dataset(dataset)\n",
    "        if initial_size > 1000:\n",
    "            data = generate_sample_set(data, 1000)\n",
    "        row_number = data.shape[0]\n",
    "        (\n",
    "            len_set_of_pairs,\n",
    "            global_list_of_relevant_attributes,\n",
    "            d,\n",
    "            c,\n",
    "            alpha,\n",
    "            beta,\n",
    "            actual_relevant_attributes,\n",
    "        ) = explanation_loop(data, max_distance)\n",
    "        try:\n",
    "            confidence = alpha / beta\n",
    "        except:\n",
    "            confidence = 0\n",
    "        total_confidence += confidence\n",
    "        number_of_explanatory_features_list.append(len(actual_relevant_attributes))\n",
    "    average_confidence_list.append(total_confidence / number_of_test)\n",
    "    dimension_list.append(dimension)\n",
    "    average_num_of_features_list.append(\n",
    "        sum(number_of_explanatory_features_list) / number_of_test\n",
    "    )\n",
    "    print(\n",
    "        \"Dataset:\",\n",
    "        dataset,\n",
    "        \"-dimension:\",\n",
    "        dimension,\n",
    "        \"-number of rows:\",\n",
    "        row_number,\n",
    "        \"-initial size:\",\n",
    "        initial_size,\n",
    "    )\n",
    "\n",
    "    # PRINTING EXPLANATIONS\n",
    "    print(\n",
    "        \"Dataset:\",\n",
    "        dataset,\n",
    "        \"-dimension:\",\n",
    "        dimension,\n",
    "        \"-number of rows:\",\n",
    "        row_number,\n",
    "        \"-initial size:\",\n",
    "        initial_size,\n",
    "    )\n",
    "    print(\n",
    "        \"Total pairs (a,b):\",\n",
    "        len_set_of_pairs,\n",
    "        \" -matching pairs i.e. such that a:b::c:d\",\n",
    "        beta,\n",
    "        \" -matching pairs with different classes:\",\n",
    "        alpha,\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        \"1) We have found\",\n",
    "        len(global_list_of_relevant_attributes),\n",
    "        \"relevant attributes among\",\n",
    "        dimension,\n",
    "        \"which are:\",\n",
    "        global_list_of_relevant_attributes,\n",
    "        \".\",\n",
    "    )\n",
    "    print(\"Our explanations why vector D:\", d[:-1], \"is in class\", d[-1], \":\")\n",
    "    print(\n",
    "        \"2) C\", c[:-1], \"is one of the nearest neighbours of D and C is in class\", c[-1]\n",
    "    )\n",
    "    try:\n",
    "        confidence = alpha / beta\n",
    "    except:\n",
    "        confidence = 0\n",
    "    if beta != 0:\n",
    "        print(\n",
    "            \"3) We have\",\n",
    "            int(100 * confidence),\n",
    "            \"% of confidence that attribute(s)\",\n",
    "            actual_relevant_attributes,\n",
    "            \"cause(s) the change of class.\",\n",
    "        )\n",
    "    else:\n",
    "        print(\n",
    "            \"3) We do not have any matching profile in the dataset: we cannot conclude.\"\n",
    "        )\n",
    "    print(number_of_explanatory_features_list)\n",
    "    print(\"***************************************************************\")\n",
    "\n",
    "\"\"\"\n",
    "x_labels = [\n",
    "    \"Adul.\",\n",
    "    \"Bach\",\n",
    "    \"Car\",\n",
    "    \"Ches.\",\n",
    "    \"Cont.\",\n",
    "    \"Dmft\",\n",
    "    \"Dres.\",\n",
    "    \"Mush.\",\n",
    "    \"Phis.\",\n",
    "    \"Port.\",\n",
    "    \"Scho.\",\n",
    "    \"Vote\",\n",
    "]\n",
    "bar1 = dimension_list\n",
    "color1 = \"blue\"\n",
    "label1 = \"dataset dimension\"\n",
    "bar2 = average_num_of_features_list\n",
    "color2 = \"red\"\n",
    "label2 = \"average used features\"\n",
    "y_label = \"Num of features\"\n",
    "show_bar(bar1, color1, label1, bar2, color2, label2, x_labels, y_label, legend=True)\n",
    "\n",
    "bar1 = average_confidence_list\n",
    "label1 = \"Confidence between 0 and 1\"\n",
    "bar2 = average_confidence_list\n",
    "y_label = \"Confidence between 0 and 1\"\n",
    "show_bar(bar1, color1, label1, bar2, color1, label1, x_labels, y_label, legend=False)\n",
    "\n",
    "# EXPERIMENT SAMPLE SIZE IMPACT ON HIGH DIMENSIONAL DATASET ADULT - PHISHING - PORTUGAL BANK\n",
    "#dataset=filename1\n",
    "dataset=filename9\n",
    "#dataset=filename10\n",
    "number_of_test=10\n",
    "data_init, _, _, _, _ = load_dataset(dataset)\n",
    "average_confidence_for_size_list=[]\n",
    "size_list=[500,1000,1500,2000]\n",
    "for size in size_list: #           #,1500,2000,3000,5000]:\n",
    "    print(\"SIZE:\",size)\n",
    "    total_confidence_for_size=0\n",
    "    for i in range(number_of_test):\n",
    "        #print(\"TEST:\",i)\n",
    "        data = generate_sample_set(data_init, size)\n",
    "        row_number = data.shape[0]\n",
    "        (\n",
    "            len_set_of_pairs,\n",
    "            global_list_of_relevant_attributes,\n",
    "            d,\n",
    "            c,\n",
    "            alpha,\n",
    "            beta,\n",
    "            actual_relevant_attributes,\n",
    "        ) = explanation_loop(data,max_distance)\n",
    "        try:\n",
    "            confidence = alpha / beta\n",
    "        except:\n",
    "            confidence = 0\n",
    "        total_confidence_for_size += confidence\n",
    "        print(total_confidence_for_size)\n",
    "    average_confidence_for_size= total_confidence_for_size / number_of_test\n",
    "    average_confidence_for_size_list.append(average_confidence_for_size)\n",
    "    \n",
    "print(dataset,average_confidence_for_size_list)\n",
    "\n",
    "t = [500,1000,1500,2000]:\n",
    "a = [0.7085887796414112, 0.5210526315789473, 0.7606590452661688, 0.9487870619946092]\n",
    "b = [0.6545698924731183, 0.8443478260869565, 0.5950847293887664, 0.308874439211239 ]\n",
    "c = [0.6675924096854329, 0.5203873482467506, 0.3847218357931196, 0.49149181819953736 ]\n",
    "\n",
    "plt.plot(t, list(zip(a, b, c)),label=['Adul.', 'Phis.', 'Port.']);\n",
    "#plt.plot(t, a, t, b, t, c, label=['Adul', 'Phis', 'Port'])\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
